# -*- coding: utf-8 -*-
"""MachineLearning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YhFig6mcqhUl3yKcn6ajeyGjGyADHoZK

Five Personality Traits(OCEAN)


*   Openness to experience (invite/curious vs. consistent/cautious)
*   Conscientiousness (efficient/organized vs. easy-going/carless)
*   Extroversion (outgoin/energetic vs. solitary/reserved)
*   Agreeableness (friendly/compassionate vs. challenging/detached)
*   Neuroticism (sensitive/nervous vs. secure/confident)

Importando as bibliotecas
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
from io import open
pd.options.display.max_columns=150

"""Carregando o Dataset"""

data = pd.read_csv('data-final.csv', sep='\t')

"""Verificando o Dataset"""

data.head()

"""Excluindo os atributos irrelevantes"""

data.drop(data.columns[50:110], axis=1, inplace=True)

"""Verificando novamente os dados"""

data.head()

"""Analisando Estatísticas da base de dados"""

pd.options.display.float_format="{:.2f}".format
data.describe()

"""Verificando a contagem dos registros por valor"""

data['EXT1'].value_counts()

"""Selecionando o total de registos com valor zero"""

data[(data==0.00).all(axis=1)].describe()

"""Limpando o Dataframe com apenas registros maiores que zero."""

data = data[(data > 0.00).all(axis=1)]

"""Verificando a contagem de registros por valor."""

data["EXT1"].value_counts()

!pip install yellowbrick

"""Bibliotecas Machine Learning"""

from sklearn.cluster import KMeans
from yellowbrick.cluster import KElbowVisualizer

"""Instanciando o método KMeans e o Vizualizer"""

kmeans = KMeans()
visualizer = KElbowVisualizer(kmeans, k=(2,10))

"""Selecionando uma amostra aleatória dos dados com 5000 observações."""

data_sample = data.sample(n=5000, random_state=1)

"""Executando o teste."""

visualizer.fit(data_sample)
visualizer.poof()

"""**Agrupando os participantes em 5 grupos**

Atribuindo os registros aos devidos grupos
"""

kmeans = KMeans(n_clusters=5)
k_fit = kmeans.fit(data)

"""Inserindo os rótulos dos clusters no dataframe"""

predicoes = k_fit.labels_
data['Clusters'] = predicoes

"""Verificando os dados"""

data.head()

"""**Analisando os grupos**

Qual a quantidade de observações em cada grupo?
"""

data["Clusters"].value_counts()

"""Agrupando os registros por grupos"""

data.groupby('Clusters').mean()

"""Calculando a média de cada grupo de questões para verificar um padrão.

Selecionando as colunas de cada grupo.
"""

col_list = list(data)
ext = col_list[0:10]
est = col_list[10:20]
agr = col_list[20:30]
csn = col_list[30:40]
opn = col_list[40:50]

"""Somando os valores de cada grupo"""

data_soma = pd.DataFrame()
data_soma['extroversion'] = data[ext].sum(axis=1)/10
data_soma['neurotic'] = data[est].sum(axis=1)/10
data_soma['agreeable'] = data[agr].sum(axis=1)/10
data_soma['conscientious'] = data[csn].sum(axis=1)/10
data_soma['open'] = data[opn].sum(axis=1)/10
data_soma['clusters'] = predicoes

"""Exibindo o valor médio por grupo"""

data_soma.groupby('clusters').mean()

"""Vizlualizando as médias por grupo"""

data_clusters = data_soma.groupby('clusters').mean()

plt.figure(figsize=(22,3))
for i in range(0, 5):
    plt.subplot(1,5,i+1)
    plt.bar(data_clusters.columns, data_clusters.iloc[:, i], color='blue', alpha=0.2)
    plt.plot(data_clusters.columns, data_clusters.iloc[:, i], color='red')
    plt.title('Grupo ' + str(i))
    plt.xticks(rotation=45)
    plt.ylim(0,4);

"""Instalando a biblioteca gradio"""

!pip install gradio

import gradio as gr

dicio_questions = open("questions.txt").read().split("\n")

"""Verificando os dados."""

dicio_questions

"""Limpando os dados e recuperando apenas as questões"""

questions = []
for q in dicio_questions:
  q = str(q)
  questions.append(q[q.find("\t"):].lstrip())

questions

"""Criando os inputs dinamicos para passar ao gradio"""

inputs_questions = []
for q in questions:
  obj_input = gr.inputs.Slider(minimum=1,maximum=5,step=1,default=3,label=q)
  inputs_questions.append(obj_input)

"""Verificando os inputs"""

inputs_questions

"""Criando a interface e a função predict."""

def predict(*outputs_questions):
    outputs_questions = np.array(outputs_questions).reshape(1, -1)
    return k_fit.predict(outputs_questions)

iface = gr.Interface(
                    fn = predict,
                    title = "Big Five Personality",
                    description = "Sistema para detecção de traços de personalidade.",
                    inputs = inputs_questions,
                    outputs="text")
iface.launch(share=True)